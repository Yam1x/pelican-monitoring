name: Perf + Security + Accessibility Monitoring on Prod

on:
  push:
    branches:
      - feature/*

jobs:
  validate-robots:
    runs-on: ubuntu-24.04
    timeout-minutes: 2
    steps:
      - name: Validate robots.txt & TEST SUMMARY
        id: robots_txt_validation
        run: |
          echo "Fetching robots.txt..."
          curl -sfL https://chelzoo.ru/robots.txt -o robots.txt
          echo "Reading actual content..."
          cat <<EOF > expected_robots.txt
          # *
          User-agent: *
          Disallow: /components

          # Host
          Host: https://chelzoo.ru

          # Sitemaps
          Sitemap: https://chelzoo.ru/api/get-sitemap
          EOF
          echo "Comparing with expected content..."
          if ! diff -u expected_robots.txt robots.txt; then
            echo "âŒ robots.txt does not match the expected content."
            exit 1
          fi
          echo "âœ… robots.txt matches expected content."

  jmeter-tests:
    runs-on: ubuntu-24.04
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@v4

      - name: Set up Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'
          
      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          
      - name: Install dependencies
        run: npm ci

      - name: Cache JMeter
        id: cache-jmeter
        uses: actions/cache@v4
        with:
          path: ./apache-jmeter-5.6.3
          key: jmeter-${{ runner.os }}-v5.6.3

      - name: Download JMeter if not cached
        if: steps.cache-jmeter.outputs.cache-hit != 'true'
        run: |
          wget https://dlcdn.apache.org//jmeter/binaries/apache-jmeter-5.6.3.tgz
          tar -xzf apache-jmeter-5.6.3.tgz

      - name: Add JMeter to PATH
        run: echo "$PWD/apache-jmeter-5.6.3/bin" >> $GITHUB_PATH

      - name: Create report directories
        run: |
          mkdir -p ./report
          mkdir -p ./result
          mkdir -p ./errors

      - name: Run JMeter - Home Page
        run: |
          mkdir -p ./report/home-page
          if ! jmeter -n -t ./tests/jmeter-tests/home-page.jmx \
            -l ./report/home-page/home-page.jtl \
            -Jjmeter.save.saveservice.output_format=xml \
            -Jjmeter.save.saveservice.print_field_names=true \
            -Jjmeter.save.saveservice.response_data.on_error=true \
            -Jjmeter.save.saveservice.bytes=true \
            -Jjmeter.save.saveservice.timestamp_format=ms; then
            echo "JMETER_FAIL_homePage=1" >> $GITHUB_ENV
            echo "âŒ JMeter test execution failed: Home Page" >> ./errors/summary.txt
          fi

          cp ./report/home-page/home-page.jtl ./result/home-page.jtl || true

      - name: Run JMeter - Documents Page
        run: |
          mkdir -p ./report/documents-page
          if ! jmeter -n -t ./tests/jmeter-tests/documents-page.jmx \
            -l ./report/documents-page/documents-page.jtl \
            -Jjmeter.save.saveservice.output_format=xml \
            -Jjmeter.save.saveservice.print_field_names=true \
            -Jjmeter.save.saveservice.response_data.on_error=true \
            -Jjmeter.save.saveservice.bytes=true \
            -Jjmeter.save.saveservice.sent_bytes=true \
            -Jjmeter.save.saveservice.label=true \
            -Jjmeter.save.saveservice.latency=true \
            -Jjmeter.save.saveservice.response_code=true \
            -Jjmeter.save.saveservice.response_message=true \
            -Jjmeter.save.saveservice.successful=true \
            -Jjmeter.save.saveservice.thread_counts=true \
            -Jjmeter.save.saveservice.thread_name=true \
            -Jjmeter.save.saveservice.time=true \
            -Jjmeter.save.saveservice.connect_time=true \
            -Jjmeter.save.saveservice.assertion_results_failure_message=true \
            -Jjmeter.save.saveservice.timestamp_format=ms; then
            echo "JMETER_FAIL_documentsPage=1" >> $GITHUB_ENV
            echo "âŒ JMeter test execution failed: Documents Page" >> ./errors/summary.txt
          fi

          cp ./report/documents-page/documents-page.jtl ./result/documents-page.jtl || true

      - name: Run JMeter - News Page
        run: |
          mkdir -p ./report/news-page
          if ! jmeter -n -t ./tests/jmeter-tests/news-page.jmx \
            -l ./report/news-page/news-page.jtl \
            -Jjmeter.save.saveservice.output_format=xml \
            -Jjmeter.save.saveservice.print_field_names=true \
            -Jjmeter.save.saveservice.response_data.on_error=true \
            -Jjmeter.save.saveservice.bytes=true \
            -Jjmeter.save.saveservice.timestamp_format=ms; then
            echo "JMETER_FAIL_newsPage=1" >> $GITHUB_ENV
            echo "âŒ JMeter test execution failed: News Page" >> ./errors/summary.txt
          fi

          cp ./report/news-page/news-page.jtl ./result/news-page.jtl || true
      
      # - name: Validate JMeter reports (CLICK HERE TO SEE RESULTS)
      #   run: |
      #     if ! npx tsx scripts/home-page-jmeter-validator.ts; then
      #       echo "PARSER_FAIL_homePage=1" >> $GITHUB_ENV
      #       echo "âŒ Load Test Results are FAILED: Home Page" >> ./errors/summary.txt
      #     fi

      #     if ! npx tsx scripts/documents-page-jmeter-validator.ts; then
      #       echo "PARSER_FAIL_documentsPage=1" >> $GITHUB_ENV
      #       echo "âŒ Load Test Results are FAILED: Documents Page" >> ./errors/summary.txt
      #     fi

      #     if ! npx tsx scripts/news-page-jmeter-validator.ts; then
      #       echo "PARSER_FAIL_newsPage=1" >> $GITHUB_ENV
      #       echo "âŒ Load Test Results are FAILED: News Page" >> ./errors/summary.txt
      #     fi

      - name: FINAL VALIDATION & SUMMARY TEST REPORT 
        run: |
          if ! npx tsx scripts/home-page-jmeter-validator.ts; then
            echo "PARSER_FAIL_homePage=1" >> $GITHUB_ENV
            echo "âŒ Load Test Results are FAILED: Home Page" >> ./errors/summary.txt
          fi

          if ! npx tsx scripts/documents-page-jmeter-validator.ts; then
            echo "PARSER_FAIL_documentsPage=1" >> $GITHUB_ENV
            echo "âŒ Load Test Results are FAILED: Documents Page" >> ./errors/summary.txt
          fi

          if ! npx tsx scripts/news-page-jmeter-validator.ts; then
            echo "PARSER_FAIL_newsPage=1" >> $GITHUB_ENV
            echo "âŒ Load Test Results are FAILED: News Page" >> ./errors/summary.txt
          fi

          echo "===== APACHE JMETER LOAD TESTS SUMMARY ====="
          if [ -f ./errors/summary.txt ]; then
            cat ./errors/summary.txt
            echo "========================"
            exit 1
          else
            echo "âœ… All JMeter tests and parsers passed."
          fi

    llighthouse:
      needs: jmeter-tests
      if: always()
      runs-on: ubuntu-24.04
      timeout-minutes: 5
      steps:
        - uses: actions/checkout@v4

        - name: Set up Node.js
          uses: actions/setup-node@v4
          with:
            node-version: 20

        - name: Install Lighthouse CI
          run: npm install -g @lhci/cli@0.15.x

        - name: Create Lighthouse directory
          run: mkdir -p .lighthouseci

        - name: Run Lighthouse CI (Desktop)
          run: |
            lhci autorun --config .lighthouserc.desktop.js --collect.outputPath=.lighthouseci/desktop > ./lh-desktop-logs.txt 2>&1 || true

        - name: Run Lighthouse CI (Mobile)
          run: |
            lhci autorun --config .lighthouserc.mobile.js --collect.outputPath=.lighthouseci/mobile > ./lh-mobile-logs.txt 2>&1 || true

        - name: Validate Lighthouse CI Results (Desktop)
          id: validate_desktop
          run: |
            npx ts-node ./scripts/lighthouse-desktop-validator.ts

        - name: Validate Lighthouse CI Results (Mobile)
          id: validate_mobile
          run: |
            npx ts-node ./scripts/lighthouse-mobile-validator.ts

        - name: FINAL VALIDATION & SUMMARY TEST REPORT
          if: always()
          run: |
            echo "===== LIGHTHOUSE TEST SUMMARY ====="

            echo "===== âš“ï¸Ž ðŸ’» DESKTOP LOGS ====="
            cat ./lh-desktop-logs.txt || echo "ÐÐµÑ‚ Ð»Ð¾Ð³Ð¾Ð² Desktop"
            echo "================================"

            echo "===== âš“ï¸Ž ðŸ“² MOBILE LOGS ====="
            cat ./lh-mobile-logs.txt || echo "ÐÐµÑ‚ Ð»Ð¾Ð³Ð¾Ð² Mobile"
            echo "================================"

            echo "===== âœ…/âŒ FINAL STATUS ====="
            if [ "${{ steps.validate_desktop.outcome }}" = "success" ]; then
              echo "Desktop: PASSED âœ…"
            else
              echo "Desktop: FAILED âŒ"
            fi

            if [ "${{ steps.validate_mobile.outcome }}" = "success" ]; then
              echo "Mobile: PASSED âœ…"
            else
              echo "Mobile: FAILED âŒ"
            fi
            echo "================================"

            if [ "${{ steps.validate_desktop.outcome }}" != "success" ] || [ "${{ steps.validate_mobile.outcome }}" != "success" ]; then
              exit 1
            else
              echo "âœ… All Lighthouse checks passed."
            fi

  validate-cache-headers:
    runs-on: ubuntu-24.04
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
      
      - name: Install Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Install Playwright with browsers
        run: npx playwright install --with-deps chromium
        
      - name: Run Playwright test
        run: npx playwright test tests/playwright-tests/cache-checker.spec.ts --reporter=list > test-logs.txt 2>&1
        
      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: cache-validation-results
          path: |
            results.json
            playwright-report/
            test-logs.txt  # Optional: Include the log file in artifacts for download/archive
      
      - name: FINAL VALIDATION & SUMMARY TEST REPORT
        if: always()
        run: |
          if [ -f test-logs.txt ]; then
            echo "===== Playwright Test Logs ====="
            cat test-logs.txt
            echo "================================"
          else
            echo "No test logs found."
          fi